{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 以下代码的目的在于解决【中文字符】问题\n",
    "import sys\n",
    "stdout = sys.stdout\n",
    "# 新版sys, 需要先reload(sys)再进行sys.setdefaultencoding操作\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "sys.stdout = stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "# 设置工作目录\n",
    "os.chdir('/Users/Max/PycharmProjects/user_churn_second')\n",
    "\n",
    "# visual\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "# import basic \n",
    "import numpy as np\n",
    "\n",
    "# machine learning \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import add_dummy_feature\n",
    "from sklearn import datasets\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from collections import Counter\n",
    "\n",
    "# import third-party\n",
    "import pandas as pd \n",
    "from collections import Counter\n",
    "\n",
    "# import local file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 工作流程\n",
    "\n",
    "1、读取已有的X特征集\n",
    "\n",
    "2、对X进行预处理\n",
    "\n",
    "3、异常值剔除\n",
    "\n",
    "4、得到dummy变量\n",
    "\n",
    "5、拆分测试数据集与训练数据集\n",
    "\n",
    "6、归一化\n",
    "\n",
    "7、提取重要特征\n",
    "\n",
    "8、训练模型\n",
    "\n",
    "9、保存模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、读取特征值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"output/extract_result.csv\", index_col=0).drop(['actions', 'date', 'path3', 'path4', 'path5', 'path6'], axis=1).drop_duplicates(keep='first')\n",
    "y = pd.read_csv('output/new_3days_y_2018-03-24.csv', index_col=0).drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、数据预处理部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import data_clean as dc \n",
    "from imp import reload\n",
    "reload(dc)\n",
    "dc_dc = dc.data_clean()\n",
    "X_y = pd.merge(X, y, left_on='userid', right_on='full_id', how='left')\n",
    "X_y = dc_dc.quick_correct(X_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、异常值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 异常值处理\n",
    "# kick outlier out\n",
    "# 1. outlier \n",
    "X_y = dc_dc.outlier_deal(X_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4、数据转化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 得到 dummies 变量\n",
    "y_fea = X_y.loc[:, 'y']\n",
    "X_fea = pd.get_dummies(X_y.drop(['y', 'userid', 'full_id'], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5、拆分训练&测试数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train & test \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_fea, y_fea, test_size=0.3, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6、归一化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47481, 34)\n",
      "(20350, 34)\n",
      "(67831, 34)\n"
     ]
    }
   ],
   "source": [
    "# scale \n",
    "# 归一化\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaler = scaler.transform(X_train)\n",
    "X_test_scaler = scaler.transform(X_test)\n",
    "# assert\n",
    "assert X_test_scaler.max() != 0, ('right')\n",
    "assert X_train_scaler.max() == 1, ('right')\n",
    "print np.shape(X_train)\n",
    "print np.shape(X_test)\n",
    "print np.shape(np.vstack((X_train, X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7、提取重要特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47481, 7)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "X, y = X_train, y_train\n",
    "X.shape\n",
    "\n",
    "clf_fea = ExtraTreesClassifier()\n",
    "clf_fea_fit = clf_fea.fit(X, y)\n",
    "clf_fea_fit.feature_importances_  \n",
    "\n",
    "model = SelectFromModel(clf_fea, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "X_new.shape     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('read', 0.20576607761404073),\n",
       " ('today_read_rate', 0.15321825219681842),\n",
       " ('path1', 0.12361312187667886),\n",
       " ('favorite', 0.093843027639713514),\n",
       " ('sub', 0.061463210152518391),\n",
       " ('purchase', 0.045823417858793368),\n",
       " ('share', 0.031068014490180495),\n",
       " ('weekend', 0.028412814825854456),\n",
       " ('unsub', 0.026504115817554574),\n",
       " ('SignIn', 0.021399612078795614),\n",
       " ('os_Android', 0.018020270062236873),\n",
       " ('path2', 0.013851797276811292),\n",
       " ('lucky_money', 0.013205088085282795),\n",
       " ('status_student', 0.01191311706834779),\n",
       " ('status_worker', 0.01141683012054117),\n",
       " ('gender_female', 0.010999426195619168),\n",
       " ('city_first', 0.010884763488296124),\n",
       " ('os_missing', 0.010146024362310482),\n",
       " ('gender_male', 0.009798505516090239),\n",
       " ('city_second', 0.0097499419950013485),\n",
       " ('fromchannel_badchannel', 0.0089577148433093914),\n",
       " ('city_others', 0.0083673893206318746),\n",
       " ('coin', 0.0081179018206395236),\n",
       " ('os_iOS', 0.0078811054107038522),\n",
       " ('fromchannel_Oppo', 0.0073517912453741298),\n",
       " ('fromchannel_Huawei', 0.0070604631044462515),\n",
       " ('fromchannel_Vivo', 0.0067329528538414285),\n",
       " ('status_other', 0.0065046463730986936),\n",
       " ('completed_info', 0.0064798030398804177),\n",
       " ('fromchannel_Xiaomi', 0.005933984787393533),\n",
       " ('fromchannel_Tencent', 0.0059084487147500527),\n",
       " ('gender_missing', 0.0046976365980344629),\n",
       " ('fromchannel_unknown_ios', 0.0030069499874462282),\n",
       " ('status_missing', 0.0019017831789645005)]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_features = zip(X_fea.columns, clf_fea.feature_importances_)\n",
    "clf_features_sort = sorted(clf_features, key=lambda x: x[1], reverse=True)\n",
    "clf_features_sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8、训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练模型中....\n",
      "训练完成....\n",
      "预测中....\n",
      "[0 1]\n",
      "best estimator_rf\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=0.0, min_samples_leaf=5,\n",
      "            min_samples_split=25, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=-1, oob_score=True, random_state=21,\n",
      "            verbose=0, warm_start=False)\n",
      "{'min_samples_split': 25, 'n_estimators': 100, 'min_samples_leaf': 5, 'class_weight': None}\n",
      "\n",
      "\n",
      "分析报告生成中.....\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.97      0.88     35372\n",
      "          1       0.79      0.29      0.42     12109\n",
      "\n",
      "avg / total       0.80      0.80      0.76     47481\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.96      0.86     15124\n",
      "          1       0.66      0.23      0.34      5226\n",
      "\n",
      "avg / total       0.75      0.77      0.73     20350\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.97      0.87     50496\n",
      "          1       0.75      0.27      0.40     17335\n",
      "\n",
      "avg / total       0.78      0.79      0.75     67831\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# input: X_train_f, X_test_f, y_train_f, y_test_f\n",
    "# outputs: top5 favorited buyers for each user, and sorted by pred_score\n",
    "# after that: for rest of buyers, give possible love score\n",
    "\n",
    "# Train model\n",
    "clf = RandomForestClassifier(n_estimators=50, criterion='gini', max_depth=None, min_samples_split=5, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_split=0.0, bootstrap=True, oob_score=True, n_jobs=-1, random_state=21, verbose=0, warm_start=False, class_weight='balanced')\n",
    "\n",
    "# set parameters\n",
    "parameters = dict(\n",
    "n_estimators = [95, 100, 105], \n",
    "min_samples_split = [15, 20, 25, 30],\n",
    "min_samples_leaf = [5, 10], \n",
    "class_weight = [None]\n",
    ")\n",
    "\n",
    "# set score function\n",
    "def my_custom_scorer(y_true, y_pred):\n",
    "    return recall_score(y_true, y_pred, average='micro')\n",
    "scoring = make_scorer(my_custom_scorer)\n",
    "# set \n",
    "estimator = GridSearchCV(clf,parameters, cv = 10, n_jobs=-1, scoring=scoring)\n",
    "\n",
    "# train\n",
    "print \"训练模型中....\"\n",
    "estimator.fit(X_train_scaler, y_train)\n",
    "print \"训练完成....\"\n",
    "\n",
    "print \"预测中....\"\n",
    "# predict on test\n",
    "clf_pred_y = estimator.predict(X_test_scaler)\n",
    " \n",
    "# Is our model still predicting just one class?\n",
    "# check\n",
    "print( np.unique( clf_pred_y ))\n",
    " \n",
    "# How's our accuracy?\n",
    "#print(accuracy_score(y_test, clf_pred_y))\n",
    "# 0.9744\n",
    " \n",
    "# What about AUROC?\n",
    "#prob_y = clf.predict_proba(X_test_scaler)\n",
    "#prob_y = [p[1] for p in prob_y]\n",
    "# best params\n",
    "print \"best estimator_rf\\n{}\\n{}\\n\\n\".format(estimator.best_estimator_, estimator.best_params_)\n",
    "\n",
    "# analysis report\n",
    "print \"分析报告生成中.....\"\n",
    "print(classification_report(y_train, estimator.predict(X_train_scaler)))\n",
    "print(classification_report(y_test, clf_pred_y))\n",
    "print (classification_report(np.concatenate((y_train, y_test), axis=0), estimator.predict(np.vstack((X_train_scaler, X_test_scaler))))) # favorite 2, recall is not good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9、保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['output/train_model.m']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存模型到output\n",
    "joblib.dump(estimator, \"output/train_model.m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77100737100737105"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 恢复模型并做预测\n",
    "from sklearn.externals import joblib\n",
    "recoverd_model = joblib.load(\"output/train_model.m\")\n",
    "recoverd_model.score(X_test_scaler, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'completed_info', u'SignIn', u'weekend', u'coin', u'lucky_money',\n",
       "       u'unsub', u'sub', u'purchase', u'share', u'favorite', u'read', u'path1',\n",
       "       u'path2', u'today_read_rate', u'os_Android', u'os_iOS', u'os_missing',\n",
       "       u'city_first', u'city_others', u'city_second', u'gender_female',\n",
       "       u'gender_male', u'gender_missing', u'status_missing', u'status_other',\n",
       "       u'status_student', u'status_worker', u'fromchannel_Huawei',\n",
       "       u'fromchannel_Oppo', u'fromchannel_Tencent', u'fromchannel_Vivo',\n",
       "       u'fromchannel_Xiaomi', u'fromchannel_badchannel',\n",
       "       u'fromchannel_unknown_ios'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fea.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_columns = np.loadtxt('output/model_columns', dtype='S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['completed_info', 'SignIn', 'weekend', 'coin', 'lucky_money',\n",
       "       'unsub', 'sub', 'purchase', 'share', 'favorite', 'read', 'path1',\n",
       "       'path2', 'today_read_rate', 'os_Android', 'os_iOS', 'os_missing',\n",
       "       'city_first', 'city_others', 'city_second', 'gender_female',\n",
       "       'gender_male', 'gender_missing', 'status_missing', 'status_other',\n",
       "       'status_student', 'status_worker', 'fromchannel_Huawei',\n",
       "       'fromchannel_Oppo', 'fromchannel_Tencent', 'fromchannel_Vivo',\n",
       "       'fromchannel_Xiaomi', 'fromchannel_badchannel',\n",
       "       'fromchannel_unknown_ios'], \n",
       "      dtype='|S23')"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
